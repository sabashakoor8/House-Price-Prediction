{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3036086,"sourceType":"datasetVersion","datasetId":1859421}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch.utils.data import DataLoader, TensorDataset\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:13:52.638362Z","iopub.execute_input":"2024-08-17T23:13:52.638896Z","iopub.status.idle":"2024-08-17T23:13:58.755724Z","shell.execute_reply.started":"2024-08-17T23:13:52.638847Z","shell.execute_reply":"2024-08-17T23:13:58.753887Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Using device: cpu\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/housing-prices-dataset/Housing.csv')\n\nprint(data.head())","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:30:44.905082Z","iopub.execute_input":"2024-08-17T23:30:44.905519Z","iopub.status.idle":"2024-08-17T23:30:44.925499Z","shell.execute_reply.started":"2024-08-17T23:30:44.905486Z","shell.execute_reply":"2024-08-17T23:30:44.924363Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n0  13300000  7420         4          2        3      yes        no       no   \n1  12250000  8960         4          4        4      yes        no       no   \n2  12250000  9960         3          2        2      yes        no      yes   \n3  12215000  7500         4          2        2      yes        no      yes   \n4  11410000  7420         4          1        2      yes       yes      yes   \n\n  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n0              no             yes        2      yes        furnished  \n1              no             yes        3       no        furnished  \n2              no              no        2      yes   semi-furnished  \n3              no             yes        3      yes        furnished  \n4              no             yes        2       no        furnished  \n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.get_dummies(data, drop_first=True)\n\nX = data.drop(columns=['price']) \ny = data['price']\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:38:17.981447Z","iopub.execute_input":"2024-08-17T23:38:17.981892Z","iopub.status.idle":"2024-08-17T23:38:18.003441Z","shell.execute_reply.started":"2024-08-17T23:38:17.981857Z","shell.execute_reply":"2024-08-17T23:38:18.001772Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32)\ny_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:39:05.092792Z","iopub.execute_input":"2024-08-17T23:39:05.093734Z","iopub.status.idle":"2024-08-17T23:39:05.100783Z","shell.execute_reply.started":"2024-08-17T23:39:05.093695Z","shell.execute_reply":"2024-08-17T23:39:05.099415Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntest_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:39:07.435536Z","iopub.execute_input":"2024-08-17T23:39:07.436365Z","iopub.status.idle":"2024-08-17T23:39:07.442729Z","shell.execute_reply.started":"2024-08-17T23:39:07.436324Z","shell.execute_reply":"2024-08-17T23:39:07.441536Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model = nn.Linear(X_train.shape[1], 1)\nmodel = model.to('cpu') ","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:39:32.310213Z","iopub.execute_input":"2024-08-17T23:39:32.311123Z","iopub.status.idle":"2024-08-17T23:39:32.318566Z","shell.execute_reply.started":"2024-08-17T23:39:32.311072Z","shell.execute_reply":"2024-08-17T23:39:32.317072Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"criterion = nn.MSELoss()  # Mean Squared Error for regression tasks\noptimizer = optim.SGD(model.parameters(), lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:39:46.473156Z","iopub.execute_input":"2024-08-17T23:39:46.473686Z","iopub.status.idle":"2024-08-17T23:39:46.480073Z","shell.execute_reply.started":"2024-08-17T23:39:46.473641Z","shell.execute_reply":"2024-08-17T23:39:46.478681Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Training the model\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    \n    for features, labels in train_loader:\n        optimizer.zero_grad()\n        outputs = model(features)\n        \n        # Calculate loss\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n    \n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:40:02.868260Z","iopub.execute_input":"2024-08-17T23:40:02.869319Z","iopub.status.idle":"2024-08-17T23:40:04.690034Z","shell.execute_reply.started":"2024-08-17T23:40:02.869271Z","shell.execute_reply":"2024-08-17T23:40:04.688900Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Epoch [1/100], Loss: 15661489342756.5723\nEpoch [2/100], Loss: 5560536381147.4287\nEpoch [3/100], Loss: 2439448217892.5713\nEpoch [4/100], Loss: 1505969105188.5715\nEpoch [5/100], Loss: 1166267145069.7144\nEpoch [6/100], Loss: 1009355730944.0000\nEpoch [7/100], Loss: 980712121197.7142\nEpoch [8/100], Loss: 970720823588.5714\nEpoch [9/100], Loss: 981632825051.4286\nEpoch [10/100], Loss: 1139012512036.5715\nEpoch [11/100], Loss: 1126783076644.5715\nEpoch [12/100], Loss: 981857295213.7142\nEpoch [13/100], Loss: 971158653220.5714\nEpoch [14/100], Loss: 975032304786.2858\nEpoch [15/100], Loss: 1045508565284.5714\nEpoch [16/100], Loss: 968422738212.5714\nEpoch [17/100], Loss: 969071500726.8572\nEpoch [18/100], Loss: 1062451050788.5714\nEpoch [19/100], Loss: 967279092882.2858\nEpoch [20/100], Loss: 979738365366.8572\nEpoch [21/100], Loss: 968402711113.1428\nEpoch [22/100], Loss: 999525165348.5714\nEpoch [23/100], Loss: 969614134710.8572\nEpoch [24/100], Loss: 968188940873.1428\nEpoch [25/100], Loss: 971201241088.0000\nEpoch [26/100], Loss: 965666600082.2858\nEpoch [27/100], Loss: 963318255030.8572\nEpoch [28/100], Loss: 975523309860.5714\nEpoch [29/100], Loss: 977385369014.8572\nEpoch [30/100], Loss: 975014341485.7142\nEpoch [31/100], Loss: 962023659812.5714\nEpoch [32/100], Loss: 990155347090.2858\nEpoch [33/100], Loss: 1075968629613.7142\nEpoch [34/100], Loss: 966630379520.0000\nEpoch [35/100], Loss: 985325717796.5714\nEpoch [36/100], Loss: 964893987986.2858\nEpoch [37/100], Loss: 1006100862683.4286\nEpoch [38/100], Loss: 995903146276.5714\nEpoch [39/100], Loss: 1009073917366.8572\nEpoch [40/100], Loss: 970282831286.8572\nEpoch [41/100], Loss: 998386350957.7142\nEpoch [42/100], Loss: 968307179520.0000\nEpoch [43/100], Loss: 970148650422.8572\nEpoch [44/100], Loss: 1008818665179.4286\nEpoch [45/100], Loss: 979186604909.7142\nEpoch [46/100], Loss: 969507187565.7142\nEpoch [47/100], Loss: 1018015225563.4286\nEpoch [48/100], Loss: 967461088694.8572\nEpoch [49/100], Loss: 975746173220.5714\nEpoch [50/100], Loss: 968214377033.1428\nEpoch [51/100], Loss: 1010122771894.8572\nEpoch [52/100], Loss: 962803283968.0000\nEpoch [53/100], Loss: 964438575104.0000\nEpoch [54/100], Loss: 979739320320.0000\nEpoch [55/100], Loss: 965349906724.5714\nEpoch [56/100], Loss: 979469028205.7142\nEpoch [57/100], Loss: 973438417773.7142\nEpoch [58/100], Loss: 1024770568777.1428\nEpoch [59/100], Loss: 994290958336.0000\nEpoch [60/100], Loss: 980791851885.7142\nEpoch [61/100], Loss: 966641844224.0000\nEpoch [62/100], Loss: 969193880429.7142\nEpoch [63/100], Loss: 1004020501942.8572\nEpoch [64/100], Loss: 973126645467.4286\nEpoch [65/100], Loss: 965331095844.5714\nEpoch [66/100], Loss: 977154421321.1428\nEpoch [67/100], Loss: 984420220928.0000\nEpoch [68/100], Loss: 1026536259584.0000\nEpoch [69/100], Loss: 966145112941.7142\nEpoch [70/100], Loss: 998419592923.4286\nEpoch [71/100], Loss: 967815926930.2858\nEpoch [72/100], Loss: 990701805568.0000\nEpoch [73/100], Loss: 987187370861.7142\nEpoch [74/100], Loss: 967109959094.8572\nEpoch [75/100], Loss: 972027957833.1428\nEpoch [76/100], Loss: 965179437641.1428\nEpoch [77/100], Loss: 963144110957.7142\nEpoch [78/100], Loss: 967904569051.4286\nEpoch [79/100], Loss: 979390604434.2858\nEpoch [80/100], Loss: 963773621942.8572\nEpoch [81/100], Loss: 969613401526.8572\nEpoch [82/100], Loss: 1000186636580.5714\nEpoch [83/100], Loss: 1008308011008.0000\nEpoch [84/100], Loss: 971111809024.0000\nEpoch [85/100], Loss: 975897487652.5714\nEpoch [86/100], Loss: 977109373513.1428\nEpoch [87/100], Loss: 963294553819.4286\nEpoch [88/100], Loss: 1012404785737.1428\nEpoch [89/100], Loss: 990021323044.5714\nEpoch [90/100], Loss: 974762720109.7142\nEpoch [91/100], Loss: 966877378267.4286\nEpoch [92/100], Loss: 969805532598.8572\nEpoch [93/100], Loss: 1008545508790.8572\nEpoch [94/100], Loss: 1044974464438.8572\nEpoch [95/100], Loss: 973501664694.8572\nEpoch [96/100], Loss: 999427028114.2858\nEpoch [97/100], Loss: 971012257499.4286\nEpoch [98/100], Loss: 965566755401.1428\nEpoch [99/100], Loss: 966365455506.2858\nEpoch [100/100], Loss: 976680820736.0000\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\npredictions = []\n\nwith torch.no_grad():\n    for features, labels in test_loader:\n        outputs = model(features)\n        predictions.append(outputs.numpy())\n\npredictions = np.concatenate(predictions, axis=0)\n\nmse = criterion(torch.tensor(predictions), y_test_tensor)\nprint(f'Mean Squared Error on the test set: {mse.item():.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:40:29.661146Z","iopub.execute_input":"2024-08-17T23:40:29.661633Z","iopub.status.idle":"2024-08-17T23:40:29.672656Z","shell.execute_reply.started":"2024-08-17T23:40:29.661585Z","shell.execute_reply":"2024-08-17T23:40:29.671427Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Mean Squared Error on the test set: 1773550567424.0000\n","output_type":"stream"}]}]}